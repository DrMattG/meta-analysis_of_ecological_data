# Random effects meta-analysis

## A brief introduction to random effects models in meta-analysis  
While fixed effects models are often thought of as the building blocks to meta-analysis, their strict assumptions (e.g., that all effect sizes come from the same underlying population) make them somewhat unrealistic starting points for ecological meta-analyses. As [@koricheva_handbook_2013] point out, we tend to use random effects models in ecological meta-analysis because even though the main effect we are investigating might be consistent across studies (e.g., changes in species richness) we want to also account for variation that comes from the individual studies that comprise our meta-analysis.


Unlike clinical trial data that are common in medical research and take place under highly controlled experimental contexts, ecological meta-research is less consistent in experimental design and so we tend to use random-effect models because of their more relaxed assumptions.  

Random effects models account for the variation we get both **within** a study as well as **between** the many different studies in our meta-analysis.

Examples of random effects models in meta-analysis are plentiful, and researchers often begin with a random effects model, then progress onto more complex models that incorporate other variables from the data they've extracted.  A study by [@Murphy2014-nt] used a random effects model and aggregated over 300 effect sizes to find that in habitats with human disturbance, there was an average 18% decrease in species richness. In another meta-analysis, more focused on invasive species impacts, [@Cameron2016-yj] brought together 112 articles and found that decomposition of leaf litter increased by 41% when invasive invertebrates were present in study sites. 

## Random effects model example  
Just like in the previous chapter, we'll use the example dataset for this book to walk through the steps involved in running and interpreting a random effects model in R. Then, we'll plot the results in a forest plot.  

First, we'll load in the `metafor` library which we'll use to run our models.

```{r}
library(metafor)
```

Next, be sure you have the dataframe `RR_effect_sizes` in your R environment. You can always re-run the R code that is in chapters 1 and 2 of this book.

The code below should look vaguely familiar from the last chapter on fixed-effects meta-analyses. That's because we're using the same function from the `metafor` package called `rma`.  Since we've already calculated an effect size for every pair of measurements in our database (i.e., invaded AND uninvaded richness) we'll use those in our modeling below. The column representing effect sizes is called `yi` in our dataframe, and each effect size has its own variance measure under the column `vi`.

```{r}
random_effect_model_results <- rma(yi, # this is the effect size from each row in database
                                   vi, # measure of variance from each row in database
                                   method = "REML", # Using  a REML estimator which is common for random effect meta-analyses
                                   slab = paste(lastname, publication_year, sep = ""), # This line of code prepares study labels for the forest plot we'll create at the end of the chapter
                                   data = RR_effect_sizes) # Let R know the dataframe we'll use for our model calculations
```

Because some measures of variation were listed as NA in our `RR_effect_sizes` dataframe, those entries will be dropped from our model.  

Now, let's look at the results of our random effects meta-analysis. 

```{r}
random_effect_model_results
```

Initially, you'll notice we get a few new metrics in this output when compared to the fixed-effects model. Let's focus in on the output that's relatively similar for now.  Under the `Model Results` section you see that we get a summary effect size of `r round(random_effect_model_results$b, 4)`. Because the effect size is negative here, this indicates that we see an average decrease in species richness (the metric all of the articles in our meta-analysis measured) in invaded sites compared to control sites. This is a significant decrease in richness seeing that the p-value is <0.0001. We can also see the average decrease in richness is significant because the confidence interval produced by this random effects model does not include 0 (CI = `r round(random_effect_model_results$ci.lb, 4)`, `r round(random_effect_model_results$ci.ub, 4)`)

In order to see how the random effects model works a bit more clearly, we'll use another function in the `metafor` package called `rma.mv`. The results from the `rma` function and this `rma.mv` will be the same. The difference is that when using `rma.mv` we have to indicate that we would like the model to account for random effects at the "effect size" level of our database.  

This first line of code creates a new column in the `RR_effect_sizes` that just numbers every row in our database.  
```{r}
RR_effect_sizes$ID <- seq.int(nrow(RR_effect_sizes))
```

Now, here's the syntax for the `rma.mv` function. First, we specify the effect size column `yi` and the variance `vi`. Then we assign the random effect to every row in database, fortunately, we just created the `ID` variable which makes this easy using the syntax `random = ~1 | ID`. And lastly, we have to tell the function to pull all of these variables or columns from the dataframe `RR_effect_sizes`.  

```{r}
random_effect_model_results_again <- rma.mv(yi, vi, random = ~ 1 | ID, data = RR_effect_sizes)
random_effect_model_results_again
```

When we print the results from the `rma.mv` function, we get the exact same results for the summary effect, p-value and confidence interval that we got from the `rma` function.

## Coming soon, explanation of tau-squared and Heterogeneity tests.

## Forest plot for random effects model
